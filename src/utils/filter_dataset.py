#!/usr/bin/env python3
"""
Script to filter dataset based on word timestamps
"""

from argparse import ArgumentParser
import shutil
from tqdm import tqdm
from loguru import logger
import os
import json
import sys

# Ensure the project `src` directory is on sys.path so that `generation` can be imported
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SRC_DIR = os.path.abspath(os.path.join(CURRENT_DIR, ".."))
if SRC_DIR not in sys.path:
    sys.path.insert(0, SRC_DIR)

from generation.transcription.parakeet import Parakeet
    
if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("-d", "--data_dir", type=str, default="data/PublicFigure")
    parser.add_argument("-l", "--language", type=str, default="en")
    parser.add_argument("-b", "--batch_size", type=int, default=16)
    args = parser.parse_args()

    model = Parakeet()
    with open(os.path.join(args.data_dir, "meta.json"), "r") as f:
        meta_data = json.load(f)
    new_meta_data = []
    for i in tqdm(range(0, len(meta_data), args.batch_size)):
        batch = meta_data[i:i+args.batch_size]
        audio_paths = [os.path.join(args.data_dir, item["audio"]["real"]) for item in batch]
        try:
            texts = model.transcribe(audio_paths, args.language)
        except Exception as e:
            logger.error(f"Error transcribing audio: {e}")
            continue
        for j, item in enumerate(batch):
            item["text"] = texts[j][0]
            word_timestamps = texts[j][1]
            if len(word_timestamps) < 3:
                logger.warning(f"Word timestamps are less than 3: {word_timestamps}")
                logger.warning(f"Audio path: {audio_paths[j]}")
                if os.path.exists(audio_paths[j]):
                    shutil.move(audio_paths[j], f"{audio_paths[j]}.backup")
                if os.path.exists(audio_paths[j].replace("real", "fake")):
                    shutil.move(audio_paths[j].replace("real", "fake"), f"{audio_paths[j].replace('real', 'fake')}.backup")
            else:
                new_meta_data.append(item)
    with open(os.path.join(args.data_dir, "meta_filtered.json"), "w") as f:
        json.dump(new_meta_data, f, indent=2, ensure_ascii=False)